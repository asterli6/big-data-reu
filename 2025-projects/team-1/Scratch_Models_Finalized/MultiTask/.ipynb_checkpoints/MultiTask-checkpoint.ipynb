{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e02b87-343b-4778-b713-f9f02459e67a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "#File IO\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "#Scikit learn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Misc\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e03a34-64f3-414e-8999-65a22024c3d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#HYPERPARMETERS\n",
    "\n",
    "train_proportion = .8\n",
    "val_proportion = .1\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = .00002\n",
    "num_epochs = 20\n",
    "loss_weights = (1.0, 1.0, .01, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f9f05c-562f-4c15-8b17-49f0080ee105",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#LOAD DATASET\n",
    "\n",
    "dataset = torch.load(\"dataset.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e3671c-28aa-4aaf-a070-05e3a7c113b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#CREATE DATALOADERS\n",
    "\n",
    "train_size = int(train_proportion * len(dataset))\n",
    "val_size = int(val_proportion * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(1)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39dbdc3-332f-45bd-8966-08abf6f40d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE MODEL\n",
    "\n",
    "class MultiTaskMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cloud_mask_net = Unet(\n",
    "            encoder_name='resnet34',\n",
    "            in_channels=16,\n",
    "            classes=1,\n",
    "        )\n",
    "\n",
    "        self.cloud_phase_net = Unet(\n",
    "            encoder_name='resnet34',\n",
    "            in_channels=17,\n",
    "            classes=5,\n",
    "        )\n",
    "        self.cod_net = Unet(\n",
    "            encoder_name='resnet34',\n",
    "            in_channels=17,\n",
    "            classes=1,\n",
    "        )\n",
    "        self.cps_net = Unet(\n",
    "            encoder_name='resnet34',\n",
    "            in_channels=17,\n",
    "            classes=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        cloud_mask_pred = self.cloud_mask_net(x)  # [B,1,H,W]\n",
    "        x1 = torch.cat([x, cloud_mask_pred], dim=1)  # [B,17,H,W]\n",
    "\n",
    "        cloud_phase_pred = self.cloud_phase_net(x1)  # [B,5,H,W]\n",
    "        cod_pred = self.cod_net(x1)                # [B,1,H,W]\n",
    "        cps_pred = self.cps_net(x1)                # [B,1,H,W]\n",
    "\n",
    "        return cloud_mask_pred, cloud_phase_pred, cod_pred, cps_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a3c7a87-936f-4ae7-b6a4-7223a9fbb1fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#FINAL SETUP\n",
    "\n",
    "dev_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(dev_str)\n",
    "model = MultiTaskMLP().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "scaler = GradScaler(device = device)\n",
    "\n",
    "def unpack_labels(labels):\n",
    "    return (\n",
    "        labels[:, 0:1, :, :],             # cloud_mask → [B, H, W]\n",
    "        labels[:, 1, :, :].long(),        # cloud_phase → [B, H, W]\n",
    "        labels[:, 2:3, :, :],             # cod → [B, 1, H, W]\n",
    "        labels[:, 3:4, :, :]              # cps → [B, 1, H, W]\n",
    "    )\n",
    "\n",
    "\n",
    "train_mask_losses, train_phase_losses, train_cod_losses, train_cps_losses, train_all_losses = [], [], [], [], []\n",
    "val_mask_losses, val_phase_losses, val_cod_losses, val_cps_losses, val_all_losses = [], [], [], [], []\n",
    "\n",
    "train_mask_acc, train_phase_acc, train_cod_r2, train_cps_r2 = [], [], [], []\n",
    "val_mask_acc, val_phase_acc, val_cod_r2, val_cps_r2 = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b870ee7-ac2d-4a70-a7ec-f7196496d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN and EVALUATE FUNCTIONS\n",
    "\n",
    "def train(model, train_loader, loss_weights=(1,1,1,1)):\n",
    "    model.train()\n",
    "\n",
    "    total_instances = 0 # Count number of instances in the epoch\n",
    "    total_loss = total_loss_mask = total_loss_phase = total_loss_cod = total_loss_cps = 0 # Total loss and sublosses\n",
    "    mask_correct = phase_correct = 0 # Number of correct guesses for cloud_mask and cloud_phase\n",
    "    cod_preds, cod_labels = [], [] # Cod labels and predictions for calculating r2 \n",
    "    cps_preds, cps_labels = [], [] # Cps labels and predictions for calculating r2\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        cloud_mask_target, cloud_phase_target, cod_target, cps_target = unpack_labels(labels) # Get individual targets\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        B, _, H, W = labels.shape\n",
    "        total_instances += (B * H * W) # Count instances in batch\n",
    "        \n",
    "        with autocast(device_type=dev_str):\n",
    "            preds = model(inputs) # Model predictions\n",
    "\n",
    "            # Loss in batch\n",
    "            loss_mask = nn.BCEWithLogitsLoss()(preds[0], cloud_mask_target)\n",
    "            loss_phase = nn.CrossEntropyLoss()(preds[1], cloud_phase_target)\n",
    "            loss_cod = nn.MSELoss()(preds[2], cod_target)\n",
    "            loss_cps = nn.MSELoss()(preds[3], cps_target)\n",
    "            total_batch_loss = (\n",
    "                loss_weights[0] * loss_mask +\n",
    "                loss_weights[1] * loss_phase +\n",
    "                loss_weights[2] * loss_cod +\n",
    "                loss_weights[3] * loss_cps\n",
    "            )\n",
    "\n",
    "        # Get correct guesses for mask and phase\n",
    "        mask_preds = (torch.sigmoid(preds[0]) > 0.5).long()\n",
    "        mask_correct += (mask_preds == cloud_mask_target).sum().item()\n",
    "        phase_preds = torch.argmax(preds[1], dim=1)\n",
    "        phase_correct += (phase_preds == cloud_phase_target).sum().item()\n",
    "\n",
    "        # Get predicted and actual cod and cps\n",
    "        cod_preds.append(preds[2].cpu().detach().numpy())\n",
    "        cod_labels.append(cod_target.cpu().numpy())\n",
    "        cps_preds.append(preds[3].cpu().detach().numpy())\n",
    "        cps_labels.append(cps_target.cpu().numpy())\n",
    "            \n",
    "\n",
    "        # Update model\n",
    "        scaler.scale(total_batch_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Loss in epoch\n",
    "        total_loss += total_batch_loss.item()\n",
    "        total_loss_mask += loss_mask.item()\n",
    "        total_loss_phase += loss_phase.item()\n",
    "        total_loss_cod += loss_cod.item()\n",
    "        total_loss_cps += loss_cps.item()\n",
    "\n",
    "    # ------------------------------------ BATCH LOOP END -------------------------------------------------------------\n",
    "\n",
    "    #Accuracy for mask and phase\n",
    "    mask_accuracy = mask_correct/total_instances\n",
    "    phase_accuracy = phase_correct/total_instances\n",
    "\n",
    "    #Cod R2\n",
    "    cod_preds = np.concatenate(cod_preds).ravel()\n",
    "    cod_labels = np.concatenate(cod_labels).ravel()\n",
    "    cod_r2 = r2_score(cod_labels, cod_preds)\n",
    "\n",
    "    #Cps R2\n",
    "    cps_preds = np.concatenate(cps_preds).ravel()\n",
    "    cps_labels = np.concatenate(cps_labels).ravel()\n",
    "    cps_r2 = r2_score(cps_labels, cps_preds)\n",
    "\n",
    "    return {\n",
    "        'loss_total': total_loss / len(train_loader),\n",
    "        'loss_mask': total_loss_mask / len(train_loader),\n",
    "        'loss_phase': total_loss_phase / len(train_loader),\n",
    "        'loss_cod': total_loss_cod / len(train_loader),\n",
    "        'loss_cps': total_loss_cps / len(train_loader),\n",
    "        'acc_mask': mask_accuracy,\n",
    "        'acc_phase': phase_accuracy,\n",
    "        'r2_cod': cod_r2,\n",
    "        'r2_cps': cps_r2\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def eval(model, val_loader, loss_weights=(1,1,1,1)):\n",
    "    model.eval()\n",
    "\n",
    "    total_instances = 0 # Count number of instances in the epoch\n",
    "    total_loss = total_loss_mask = total_loss_phase = total_loss_cod = total_loss_cps = 0 # Total loss and sublosses\n",
    "    mask_correct = phase_correct = 0 # Number of correct guesses for cloud_mask and cloud_phase\n",
    "    cod_preds, cod_labels = [], [] # Cod labels and predictions for calculating r2 \n",
    "    cps_preds, cps_labels = [], [] # Cps labels and predictions for calculating r2\n",
    "\n",
    "    for inputs, labels in (val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        cloud_mask_target, cloud_phase_target, cod_target, cps_target = unpack_labels(labels) # Get individual targets\n",
    "\n",
    "        B, _, H, W = labels.shape\n",
    "        total_instances += (B * H * W) # Count instances in batch\n",
    "        \n",
    "        \n",
    "        with torch.no_grad(), autocast(device_type=dev_str):\n",
    "            preds = model(inputs) # Model predictions\n",
    "\n",
    "            # Loss in batch\n",
    "            loss_mask = nn.BCEWithLogitsLoss()(preds[0], cloud_mask_target)\n",
    "            loss_phase = nn.CrossEntropyLoss()(preds[1], cloud_phase_target)\n",
    "            loss_cod = nn.MSELoss()(preds[2], cod_target)\n",
    "            loss_cps = nn.MSELoss()(preds[3], cps_target)\n",
    "            total_batch_loss = (\n",
    "                loss_weights[0] * loss_mask +\n",
    "                loss_weights[1] * loss_phase +\n",
    "                loss_weights[2] * loss_cod +\n",
    "                loss_weights[3] * loss_cps\n",
    "            )\n",
    "\n",
    "        # Get correct guesses for mask and phase\n",
    "        mask_preds = (torch.sigmoid(preds[0]) > 0.5).long()\n",
    "        mask_correct += (mask_preds == cloud_mask_target).sum().item()\n",
    "        phase_preds = torch.argmax(preds[1], dim=1)\n",
    "        phase_correct += (phase_preds == cloud_phase_target).sum().item()\n",
    "\n",
    "        # Get predicted and actual cod and cps\n",
    "        cod_preds.append(preds[2].cpu().detach().numpy())\n",
    "        cod_labels.append(cod_target.cpu().numpy())\n",
    "        cps_preds.append(preds[3].cpu().detach().numpy())\n",
    "        cps_labels.append(cps_target.cpu().numpy())\n",
    "            \n",
    "        # Loss in epoch\n",
    "        total_loss += total_batch_loss.item()\n",
    "        total_loss_mask += loss_mask.item()\n",
    "        total_loss_phase += loss_phase.item()\n",
    "        total_loss_cod += loss_cod.item()\n",
    "        total_loss_cps += loss_cps.item()\n",
    "\n",
    "    # ------------------------------------ BATCH LOOP END -------------------------------------------------------------\n",
    "\n",
    "    #Accuracy for mask and phase\n",
    "    mask_accuracy = mask_correct/total_instances\n",
    "    phase_accuracy = phase_correct/total_instances\n",
    "\n",
    "    #Cod R2\n",
    "    cod_preds = np.concatenate(cod_preds).ravel()\n",
    "    cod_labels = np.concatenate(cod_labels).ravel()\n",
    "    cod_r2 = r2_score(cod_labels, cod_preds)\n",
    "\n",
    "    #Cps R2\n",
    "    cps_preds = np.concatenate(cps_preds).ravel()\n",
    "    cps_labels = np.concatenate(cps_labels).ravel()\n",
    "    cps_r2 = r2_score(cps_labels, cps_preds)\n",
    "\n",
    "    return {\n",
    "        'loss_total': total_loss / len(val_loader),\n",
    "        'loss_mask': total_loss_mask / len(val_loader),\n",
    "        'loss_phase': total_loss_phase / len(val_loader),\n",
    "        'loss_cod': total_loss_cod / len(val_loader),\n",
    "        'loss_cps': total_loss_cps / len(val_loader),\n",
    "        'acc_mask': mask_accuracy,\n",
    "        'acc_phase': phase_accuracy,\n",
    "        'r2_cod': cod_r2,\n",
    "        'r2_cps': cps_r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8014f4b-26c8-4ce1-bacd-ce7b283c3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN MODEL\n",
    "\n",
    "for e in range(1, num_epochs+1):\n",
    "    train_results = train(model, train_loader,) #loss_weights = loss_weights)\n",
    "    val_results = eval(model, val_loader,) #loss_weights = loss_weights)\n",
    "    \n",
    "    train_mask_losses.append(train_results['loss_mask'])\n",
    "    train_phase_losses.append(train_results['loss_phase'])\n",
    "    train_cod_losses.append(train_results['loss_cod'])\n",
    "    train_cps_losses.append(train_results['loss_cps'])\n",
    "    train_all_losses.append(train_results['loss_total'])\n",
    "\n",
    "    train_mask_acc.append(train_results['acc_mask'])\n",
    "    train_phase_acc.append(train_results['acc_phase'])\n",
    "    train_cod_r2.append(train_results['r2_cod'])\n",
    "    train_cps_r2.append(train_results['r2_cps'])\n",
    "\n",
    "    val_mask_losses.append(val_results['loss_mask'])\n",
    "    val_phase_losses.append(val_results['loss_phase'])\n",
    "    val_cod_losses.append(val_results['loss_cod'])\n",
    "    val_cps_losses.append(val_results['loss_cps'])\n",
    "    val_all_losses.append(val_results['loss_total'])\n",
    "\n",
    "    val_mask_acc.append(val_results['acc_mask'])\n",
    "    val_phase_acc.append(val_results['acc_phase'])\n",
    "    val_cod_r2.append(val_results['r2_cod'])\n",
    "    val_cps_r2.append(val_results['r2_cps'])\n",
    "\n",
    "    print(f\"Epoch: {e} | Train Loss: {train_results['loss_total']:.4f} | Val Loss: {val_results['loss_total']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764d4ec-a133-4a41-b0da-96d36ee84513",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#PLOT LOSS\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(train_mask_losses, label='Train Loss')\n",
    "plt.plot(val_mask_losses, label='Val Loss')\n",
    "plt.title('Cloud Mask Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(train_phase_losses, label='Train Loss')\n",
    "plt.plot(val_phase_losses, label='Val Loss')\n",
    "plt.title('Cloud Phase Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(train_cod_losses, label='Train Loss')\n",
    "plt.plot(val_cod_losses, label='Val Loss')\n",
    "plt.title('Cod Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(train_cps_losses, label='Train Loss')\n",
    "plt.plot(val_cps_losses, label='Val Loss')\n",
    "plt.title('Cps Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(train_all_losses, label='Train Loss')\n",
    "plt.plot(val_all_losses, label='Val Loss')\n",
    "plt.title('All Loss')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(\"./graphs/cloud_mask_unet_loss_and_acc.png\")  \n",
    "#plt.savefig(\"./graphs/cloud_mask_unet_loss_and_acc.png\")  \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe92ea2-3137-4193-8afe-3be5dfccec4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#PLOT ACCURACY\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_mask_acc, label='Train Acc')\n",
    "plt.plot(val_mask_acc, label='Val Acc')\n",
    "plt.title('Cloud Mask Acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_phase_acc, label='Train Acc')\n",
    "plt.plot(val_phase_acc, label='Val Acc')\n",
    "plt.title('Cloud Phase Acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(train_cod_r2, label='Train R2')\n",
    "plt.plot(val_cod_r2, label='Val R2')\n",
    "plt.title('Cod R2')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(train_cps_r2, label='Train R2')\n",
    "plt.plot(val_cps_r2, label='Val R2')\n",
    "plt.title('Cps R2')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457b4c9-99ce-4477-940a-50fb07c3e0ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL EVALUATION — CLOUD MASK\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        cloud_mask_target, _, _, _ = unpack_labels(labels)\n",
    "        cloud_mask_pred, _, _, _ = model(images)\n",
    "\n",
    "        probs = torch.sigmoid(cloud_mask_pred)\n",
    "        preds = (probs > 0.5).long()\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(cloud_mask_target.cpu().numpy())\n",
    "\n",
    "# Flatten predictions and labels\n",
    "all_preds = np.concatenate([p.flatten() for p in all_preds])\n",
    "all_labels = np.concatenate([l.flatten() for l in all_labels])\n",
    "\n",
    "# Classification report and IoU\n",
    "report = classification_report(\n",
    "    all_labels, all_preds,\n",
    "    labels=[0, 1],\n",
    "    digits=3,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "\n",
    "# Output\n",
    "print(\"CLOUD MASK REPORT:\\n\", classification_report(all_labels, all_preds, labels=[0, 1], digits=3))\n",
    "print(\"CONFUSION MATRIX:\\n\", confusion_matrix(all_labels, all_preds, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c8df5-d921-4eac-a8b9-b14e2eb94ea0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL EVALUATION — CLOUD PHASE\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _, cloud_phase_target, _, _ = unpack_labels(labels)\n",
    "        _, cloud_phase_pred, _, _ = model(images)\n",
    "        preds = torch.argmax(cloud_phase_pred, dim=1)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(cloud_phase_target.cpu().numpy())\n",
    "        \n",
    "# Flatten predictions and labels\n",
    "all_preds = np.concatenate([p.flatten() for p in all_preds])\n",
    "all_labels = np.concatenate([l.flatten() for l in all_labels])\n",
    "\n",
    "# Classification report and IoU\n",
    "report = classification_report(all_labels, all_preds, digits=3, output_dict=True)\n",
    "f1_scores = np.array([report[str(i)]['f1-score'] for i in range(num_classes)])\n",
    "supports = np.array([report[str(i)]['support'] for i in range(num_classes)])\n",
    "iou = f1_scores / (2 - f1_scores)\n",
    "\n",
    "# Output\n",
    "print(\"CLOUD PHASE REPORT:\\n\", classification_report(all_labels, all_preds, digits=3))\n",
    "print(\"CONFUSION MATRIX:\\n\", confusion_matrix(all_labels, all_preds))\n",
    "print(\"\\nIOU:\", iou)\n",
    "print(\"Unweighted IoU:\", np.mean(iou))\n",
    "print(\"Weighted IoU:\", np.average(iou, weights=supports))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6fa71-7e74-4f1b-8806-3891c037a1b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL EVALUATION — CLOUD OPTICAL DISTANCE\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _, _, cod_target, _ = unpack_labels(labels)\n",
    "        _, _, cod_pred, _ = model(images)\n",
    "        \n",
    "        all_preds.append(cod_pred.cpu().numpy().reshape(-1))\n",
    "        all_labels.append(cod_target.cpu().numpy().reshape(-1))\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(\"r2:\", r2_score(all_labels, all_preds))\n",
    "print(\"MSE:\", mean_squared_error(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968dce8-90fe-44ce-a25a-4e7125b0dfaf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL EVALUATION — CLOUD PARTICLE SIZE\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _, _, _, cps_target = unpack_labels(labels)\n",
    "        _, _, _, cps_pred = model(images)\n",
    "        \n",
    "        all_preds.append(cps_pred.cpu().numpy().reshape(-1))\n",
    "        all_labels.append(cps_target.cpu().numpy().reshape(-1))\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(\"r2:\", r2_score(all_labels, all_preds))\n",
    "print(\"MSE:\", mean_squared_error(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7c172-8b04-4fa5-83fc-1abf82a91b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(test_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "_, cloud_phase_target, _, _ = unpack_labels(labels)\n",
    "_, cloud_phase_pred, _, _ = model(images)\n",
    "preds = torch.argmax(cloud_phase_pred, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90c778-93f2-4ebb-aadc-562b4177112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = images[0].cpu().numpy()\n",
    "my_image = np.transpose(my_image, (1, 2, 0))\n",
    "phase_pred = preds[0].cpu().numpy()\n",
    "phase_target = cloud_phase_target[0].cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with Dataset('image1.nc', 'w', format='NETCDF4') as ds:\n",
    "    ds.createDimension('x', my_image.shape[0])\n",
    "    ds.createDimension('y', my_image.shape[1])\n",
    "    ds.createDimension('band', my_image.shape[2])\n",
    "\n",
    "    var = ds.createVariable('radiance', 'f4', ('x', 'y', 'band'))\n",
    "    var[:] = my_image\n",
    "\n",
    "    var.units = 'unknown'  # optional metadata\n",
    "\n",
    "with Dataset('image2.nc', 'w', format='NETCDF4') as ds:\n",
    "    ds.createDimension('x', phase_pred.shape[0])\n",
    "    ds.createDimension('y', phase_pred.shape[1])\n",
    "\n",
    "    var = ds.createVariable('prediction', 'f4', ('x', 'y'))\n",
    "    var[:] = phase_pred\n",
    "\n",
    "    var.units = 'unknown'  # optional metadata\n",
    "\n",
    "\n",
    "with Dataset('image3.nc', 'w', format='NETCDF4') as ds:\n",
    "    ds.createDimension('x', phase_target.shape[0])\n",
    "    ds.createDimension('y', phase_target.shape[1])\n",
    "\n",
    "    var = ds.createVariable('target', 'f4', ('x', 'y'))\n",
    "    var[:] = phase_target\n",
    "\n",
    "    var.units = 'unknown'  # optional metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb8600-6223-4768-9f5c-56a5550eec90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
