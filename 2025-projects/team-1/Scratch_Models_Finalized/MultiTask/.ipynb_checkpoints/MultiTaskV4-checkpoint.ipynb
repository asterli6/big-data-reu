{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e02b87-343b-4778-b713-f9f02459e67a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "#File IO\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "#Scikit learn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Misc\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e03a34-64f3-414e-8999-65a22024c3d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#HYPERPARMETERS\n",
    "\n",
    "train_proportion = .8\n",
    "val_proportion = .1\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = .00002\n",
    "num_epochs = 50\n",
    "loss_weights = (1.0, 1.0, .01, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f9f05c-562f-4c15-8b17-49f0080ee105",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#LOAD DATASET\n",
    "\n",
    "dataset = torch.load(\"dataset.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e3671c-28aa-4aaf-a070-05e3a7c113b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#CREATE DATALOADERS\n",
    "\n",
    "train_size = int(train_proportion * len(dataset))\n",
    "val_size = int(val_proportion * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(1)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39dbdc3-332f-45bd-8966-08abf6f40d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE MODEL\n",
    "\n",
    "class MultiTaskCNN(nn.Module):\n",
    "    def __init__(self, in_channels=16):\n",
    "        super().__init__()\n",
    "\n",
    "        # Shared feature extractor\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Heads\n",
    "        self.mask_head = nn.Conv2d(256, 1, kernel_size=1)      # Binary classification\n",
    "        self.phase_head = nn.Conv2d(256, 5, kernel_size=1)     # Multi-class classification\n",
    "        self.cod_head = nn.Conv2d(256, 1, kernel_size=1)       # Regression\n",
    "        self.cps_head = nn.Conv2d(256, 1, kernel_size=1)       # Regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_feats = self.shared(x)\n",
    "\n",
    "        cloud_mask_logits = self.mask_head(shared_feats)          # [B, 1, H, W]\n",
    "        cloud_mask = torch.sigmoid(cloud_mask_logits)             # Convert to probabilities\n",
    "\n",
    "        # Create binary mask: 1 where mask > 0.5, else 0\n",
    "        binary_mask = (cloud_mask > 0.5).float()                  # [B, 1, H, W]\n",
    "\n",
    "        # Other heads\n",
    "        cloud_phase_logits = self.phase_head(shared_feats)        # [B, 5, H, W]\n",
    "        cod_pred = self.cod_head(shared_feats)                    # [B, 1, H, W]\n",
    "        cps_pred = self.cps_head(shared_feats)                    # [B, 1, H, W]\n",
    "\n",
    "        # Apply mask logic: zero out other outputs where mask == 0\n",
    "        cloud_phase_logits = cloud_phase_logits * binary_mask     # broadcast on [B, 5, H, W]\n",
    "        cod_pred = cod_pred * binary_mask\n",
    "        cps_pred = cps_pred * binary_mask\n",
    "\n",
    "        return cloud_mask_logits, cloud_phase_logits, cod_pred, cps_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3c7a87-936f-4ae7-b6a4-7223a9fbb1fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#FINAL SETUP\n",
    "\n",
    "dev_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(dev_str)\n",
    "model = MultiTaskCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "scaler = GradScaler(device = device)\n",
    "\n",
    "def unpack_labels(labels):\n",
    "    return (\n",
    "        labels[:, 0:1, :, :],             # cloud_mask → [B, H, W]\n",
    "        labels[:, 1, :, :].long(),        # cloud_phase → [B, H, W]\n",
    "        labels[:, 2:3, :, :],             # cod → [B, 1, H, W]\n",
    "        labels[:, 3:4, :, :]              # cps → [B, 1, H, W]\n",
    "    )\n",
    "\n",
    "\n",
    "train_mask_losses, train_phase_losses, train_cod_losses, train_cps_losses, train_all_losses = [], [], [], [], []\n",
    "val_mask_losses, val_phase_losses, val_cod_losses, val_cps_losses, val_all_losses = [], [], [], [], []\n",
    "\n",
    "train_mask_acc, train_phase_acc, train_cod_r2, train_cps_r2 = [], [], [], []\n",
    "val_mask_acc, val_phase_acc, val_cod_r2, val_cps_r2 = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b870ee7-ac2d-4a70-a7ec-f7196496d44c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#TRAIN and EVALUATE FUNCTIONS\n",
    "\n",
    "def train(model, train_loader, loss_weights=(1,1,1,1)):\n",
    "    model.train()\n",
    "\n",
    "    total_instances = 0 # Count number of instances in the epoch\n",
    "    total_loss = total_loss_mask = total_loss_phase = total_loss_cod = total_loss_cps = 0 # Total loss and sublosses\n",
    "    mask_correct = phase_correct = 0 # Number of correct guesses for cloud_mask and cloud_phase\n",
    "    cod_preds, cod_labels = [], [] # Cod labels and predictions for calculating r2 \n",
    "    cps_preds, cps_labels = [], [] # Cps labels and predictions for calculating r2\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        cloud_mask_target, cloud_phase_target, cod_target, cps_target = unpack_labels(labels) # Get individual targets\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        B, _, H, W = labels.shape\n",
    "        total_instances += (B * H * W) # Count instances in batch\n",
    "        \n",
    "        with autocast(device_type=dev_str):\n",
    "            preds = model(inputs) # Model predictions\n",
    "\n",
    "            # Loss in batch\n",
    "            loss_mask = nn.BCEWithLogitsLoss()(preds[0], cloud_mask_target)\n",
    "            loss_phase = nn.CrossEntropyLoss()(preds[1], cloud_phase_target)\n",
    "            loss_cod = nn.MSELoss()(preds[2], cod_target)\n",
    "            loss_cps = nn.MSELoss()(preds[3], cps_target)\n",
    "            total_batch_loss = (\n",
    "                loss_weights[0] * loss_mask +\n",
    "                loss_weights[1] * loss_phase +\n",
    "                loss_weights[2] * loss_cod +\n",
    "                loss_weights[3] * loss_cps\n",
    "            )\n",
    "\n",
    "        # Get correct guesses for mask and phase\n",
    "        mask_preds = (torch.sigmoid(preds[0]) > 0.5).long()\n",
    "        mask_correct += (mask_preds == cloud_mask_target).sum().item()\n",
    "        phase_preds = torch.argmax(preds[1], dim=1)\n",
    "        phase_correct += (phase_preds == cloud_phase_target).sum().item()\n",
    "\n",
    "        # Get predicted and actual cod and cps\n",
    "        cod_preds.append(preds[2].cpu().detach().numpy())\n",
    "        cod_labels.append(cod_target.cpu().numpy())\n",
    "        cps_preds.append(preds[3].cpu().detach().numpy())\n",
    "        cps_labels.append(cps_target.cpu().numpy())\n",
    "            \n",
    "\n",
    "        # Update model\n",
    "        scaler.scale(total_batch_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Loss in epoch\n",
    "        total_loss += total_batch_loss.item()\n",
    "        total_loss_mask += loss_mask.item()\n",
    "        total_loss_phase += loss_phase.item()\n",
    "        total_loss_cod += loss_cod.item()\n",
    "        total_loss_cps += loss_cps.item()\n",
    "\n",
    "    # ------------------------------------ BATCH LOOP END -------------------------------------------------------------\n",
    "\n",
    "    #Accuracy for mask and phase\n",
    "    mask_accuracy = mask_correct/total_instances\n",
    "    phase_accuracy = phase_correct/total_instances\n",
    "\n",
    "    #Cod R2\n",
    "    cod_preds = np.concatenate(cod_preds).ravel()\n",
    "    cod_labels = np.concatenate(cod_labels).ravel()\n",
    "    cod_r2 = r2_score(cod_labels, cod_preds)\n",
    "\n",
    "    #Cps R2\n",
    "    cps_preds = np.concatenate(cps_preds).ravel()\n",
    "    cps_labels = np.concatenate(cps_labels).ravel()\n",
    "    cps_r2 = r2_score(cps_labels, cps_preds)\n",
    "\n",
    "    return {\n",
    "        'loss_total': total_loss / len(train_loader),\n",
    "        'loss_mask': total_loss_mask / len(train_loader),\n",
    "        'loss_phase': total_loss_phase / len(train_loader),\n",
    "        'loss_cod': total_loss_cod / len(train_loader),\n",
    "        'loss_cps': total_loss_cps / len(train_loader),\n",
    "        'acc_mask': mask_accuracy,\n",
    "        'acc_phase': phase_accuracy,\n",
    "        'r2_cod': cod_r2,\n",
    "        'r2_cps': cps_r2\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def eval(model, val_loader, loss_weights=(1,1,1,1)):\n",
    "    model.eval()\n",
    "\n",
    "    total_instances = 0 # Count number of instances in the epoch\n",
    "    total_loss = total_loss_mask = total_loss_phase = total_loss_cod = total_loss_cps = 0 # Total loss and sublosses\n",
    "    mask_correct = phase_correct = 0 # Number of correct guesses for cloud_mask and cloud_phase\n",
    "    cod_preds, cod_labels = [], [] # Cod labels and predictions for calculating r2 \n",
    "    cps_preds, cps_labels = [], [] # Cps labels and predictions for calculating r2\n",
    "\n",
    "    for inputs, labels in (val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        cloud_mask_target, cloud_phase_target, cod_target, cps_target = unpack_labels(labels) # Get individual targets\n",
    "\n",
    "        B, _, H, W = labels.shape\n",
    "        total_instances += (B * H * W) # Count instances in batch\n",
    "        \n",
    "        \n",
    "        with torch.no_grad(), autocast(device_type=dev_str):\n",
    "            preds = model(inputs) # Model predictions\n",
    "\n",
    "            # Loss in batch\n",
    "            loss_mask = nn.BCEWithLogitsLoss()(preds[0], cloud_mask_target)\n",
    "            loss_phase = nn.CrossEntropyLoss()(preds[1], cloud_phase_target)\n",
    "            loss_cod = nn.MSELoss()(preds[2], cod_target)\n",
    "            loss_cps = nn.MSELoss()(preds[3], cps_target)\n",
    "            total_batch_loss = (\n",
    "                loss_weights[0] * loss_mask +\n",
    "                loss_weights[1] * loss_phase +\n",
    "                loss_weights[2] * loss_cod +\n",
    "                loss_weights[3] * loss_cps\n",
    "            )\n",
    "\n",
    "        # Get correct guesses for mask and phase\n",
    "        mask_preds = (torch.sigmoid(preds[0]) > 0.5).long()\n",
    "        mask_correct += (mask_preds == cloud_mask_target).sum().item()\n",
    "        phase_preds = torch.argmax(preds[1], dim=1)\n",
    "        phase_correct += (phase_preds == cloud_phase_target).sum().item()\n",
    "\n",
    "        # Get predicted and actual cod and cps\n",
    "        cod_preds.append(preds[2].cpu().detach().numpy())\n",
    "        cod_labels.append(cod_target.cpu().numpy())\n",
    "        cps_preds.append(preds[3].cpu().detach().numpy())\n",
    "        cps_labels.append(cps_target.cpu().numpy())\n",
    "            \n",
    "        # Loss in epoch\n",
    "        total_loss += total_batch_loss.item()\n",
    "        total_loss_mask += loss_mask.item()\n",
    "        total_loss_phase += loss_phase.item()\n",
    "        total_loss_cod += loss_cod.item()\n",
    "        total_loss_cps += loss_cps.item()\n",
    "\n",
    "    # ------------------------------------ BATCH LOOP END -------------------------------------------------------------\n",
    "\n",
    "    #Accuracy for mask and phase\n",
    "    mask_accuracy = mask_correct/total_instances\n",
    "    phase_accuracy = phase_correct/total_instances\n",
    "\n",
    "    #Cod R2\n",
    "    cod_preds = np.concatenate(cod_preds).ravel()\n",
    "    cod_labels = np.concatenate(cod_labels).ravel()\n",
    "    cod_r2 = r2_score(cod_labels, cod_preds)\n",
    "\n",
    "    #Cps R2\n",
    "    cps_preds = np.concatenate(cps_preds).ravel()\n",
    "    cps_labels = np.concatenate(cps_labels).ravel()\n",
    "    cps_r2 = r2_score(cps_labels, cps_preds)\n",
    "\n",
    "    return {\n",
    "        'loss_total': total_loss / len(val_loader),\n",
    "        'loss_mask': total_loss_mask / len(val_loader),\n",
    "        'loss_phase': total_loss_phase / len(val_loader),\n",
    "        'loss_cod': total_loss_cod / len(val_loader),\n",
    "        'loss_cps': total_loss_cps / len(val_loader),\n",
    "        'acc_mask': mask_accuracy,\n",
    "        'acc_phase': phase_accuracy,\n",
    "        'r2_cod': cod_r2,\n",
    "        'r2_cps': cps_r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8014f4b-26c8-4ce1-bacd-ce7b283c3639",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:30<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 271.1431 | Val Loss: 254.7181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:39<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 235.0202 | Val Loss: 205.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:35<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 220.3540 | Val Loss: 187.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:36<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 210.2730 | Val Loss: 206.2323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:31<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 202.9861 | Val Loss: 178.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:24<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 196.8585 | Val Loss: 194.2941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:29<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 191.4619 | Val Loss: 173.4021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 186.6996 | Val Loss: 185.8151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:17<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 182.3122 | Val Loss: 176.3728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:16<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 177.7419 | Val Loss: 154.1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:18<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 173.3193 | Val Loss: 156.9480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:16<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 168.9732 | Val Loss: 132.8507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:19<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 164.7519 | Val Loss: 164.3162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:18<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 161.0266 | Val Loss: 158.5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:20<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 156.8339 | Val Loss: 140.5637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:21<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 152.9026 | Val Loss: 130.6007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:13<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss: 149.1331 | Val Loss: 138.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:17<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss: 145.9188 | Val Loss: 122.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:21<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss: 142.7246 | Val Loss: 118.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:15<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss: 139.3440 | Val Loss: 136.5994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:32<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss: 136.1711 | Val Loss: 100.6048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:26<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss: 133.2170 | Val Loss: 121.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:28<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss: 130.2481 | Val Loss: 150.5054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:30<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss: 127.6388 | Val Loss: 165.2654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:08<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss: 125.2474 | Val Loss: 124.6097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:55<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss: 122.4383 | Val Loss: 144.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:28<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss: 120.1821 | Val Loss: 96.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:27<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss: 117.7636 | Val Loss: 115.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:59<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss: 115.6592 | Val Loss: 105.7356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:38<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Train Loss: 113.7465 | Val Loss: 130.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:20<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Train Loss: 111.4708 | Val Loss: 101.5216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:21<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Train Loss: 109.5046 | Val Loss: 95.2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:35<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Train Loss: 107.5189 | Val Loss: 128.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Train Loss: 106.2419 | Val Loss: 106.7997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:36<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Train Loss: 104.2420 | Val Loss: 101.1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:41<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Train Loss: 102.6823 | Val Loss: 127.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:27<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Train Loss: 101.2586 | Val Loss: 94.7942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:31<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Train Loss: 99.5064 | Val Loss: 102.3397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:36<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Train Loss: 98.2907 | Val Loss: 160.3808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:33<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Train Loss: 97.0845 | Val Loss: 115.2522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:19<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Train Loss: 95.8348 | Val Loss: 102.8815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:35<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | Train Loss: 94.5568 | Val Loss: 98.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:36<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Train Loss: 93.7314 | Val Loss: 97.7114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:39<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 | Train Loss: 92.4806 | Val Loss: 99.9631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:57<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | Train Loss: 91.6275 | Val Loss: 92.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:14<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Train Loss: 90.8914 | Val Loss: 100.5348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:28<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 | Train Loss: 90.1255 | Val Loss: 93.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:18<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Train Loss: 89.6174 | Val Loss: 86.1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:42<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 | Train Loss: 89.2823 | Val Loss: 116.7973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 20/94 [00:24<01:47,  1.45s/it]"
     ]
    }
   ],
   "source": [
    "#TRAIN MODEL\n",
    "\n",
    "for e in range(1, num_epochs+1):\n",
    "    train_results = train(model, train_loader,) #loss_weights = loss_weights)\n",
    "    val_results = eval(model, val_loader,) #loss_weights = loss_weights)\n",
    "    \n",
    "    train_mask_losses.append(train_results['loss_mask'])\n",
    "    train_phase_losses.append(train_results['loss_phase'])\n",
    "    train_cod_losses.append(train_results['loss_cod'])\n",
    "    train_cps_losses.append(train_results['loss_cps'])\n",
    "    train_all_losses.append(train_results['loss_total'])\n",
    "\n",
    "    train_mask_acc.append(train_results['acc_mask'])\n",
    "    train_phase_acc.append(train_results['acc_phase'])\n",
    "    train_cod_r2.append(train_results['r2_cod'])\n",
    "    train_cps_r2.append(train_results['r2_cps'])\n",
    "\n",
    "    val_mask_losses.append(val_results['loss_mask'])\n",
    "    val_phase_losses.append(val_results['loss_phase'])\n",
    "    val_cod_losses.append(val_results['loss_cod'])\n",
    "    val_cps_losses.append(val_results['loss_cps'])\n",
    "    val_all_losses.append(val_results['loss_total'])\n",
    "\n",
    "    val_mask_acc.append(val_results['acc_mask'])\n",
    "    val_phase_acc.append(val_results['acc_phase'])\n",
    "    val_cod_r2.append(val_results['r2_cod'])\n",
    "    val_cps_r2.append(val_results['r2_cps'])\n",
    "\n",
    "    print(f\"Epoch: {e} | Train Loss: {train_results['loss_total']:.4f} | Val Loss: {val_results['loss_total']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764d4ec-a133-4a41-b0da-96d36ee84513",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#PLOT LOSS\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(train_mask_losses, label='Train Loss')\n",
    "plt.plot(val_mask_losses, label='Val Loss')\n",
    "plt.title('Cloud Mask Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(train_phase_losses, label='Train Loss')\n",
    "plt.plot(val_phase_losses, label='Val Loss')\n",
    "plt.title('Cloud Phase Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(train_cod_losses, label='Train Loss')\n",
    "plt.plot(val_cod_losses, label='Val Loss')\n",
    "plt.title('Cod Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(train_cps_losses, label='Train Loss')\n",
    "plt.plot(val_cps_losses, label='Val Loss')\n",
    "plt.title('Cps Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(train_all_losses, label='Train Loss')\n",
    "plt.plot(val_all_losses, label='Val Loss')\n",
    "plt.title('All Loss')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(\"./graphs/cloud_mask_unet_loss_and_acc.png\")  \n",
    "#plt.savefig(\"./graphs/cloud_mask_unet_loss_and_acc.png\")  \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe92ea2-3137-4193-8afe-3be5dfccec4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#PLOT ACCURACY\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_mask_acc, label='Train Acc')\n",
    "plt.plot(val_mask_acc, label='Val Acc')\n",
    "plt.title('Cloud Mask Acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_phase_acc, label='Train Acc')\n",
    "plt.plot(val_phase_acc, label='Val Acc')\n",
    "plt.title('Cloud Phase Acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(train_cod_r2, label='Train R2')\n",
    "plt.plot(val_cod_r2, label='Val R2')\n",
    "plt.title('Cod R2')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(train_cps_r2, label='Train R2')\n",
    "plt.plot(val_cps_r2, label='Val R2')\n",
    "plt.title('Cps R2')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457b4c9-99ce-4477-940a-50fb07c3e0ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL EVALUATION — CLOUD MASK\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        cloud_mask_target, _, _, _ = unpack_labels(labels)\n",
    "        cloud_mask_pred, _, _, _ = model(images)\n",
    "\n",
    "        probs = torch.sigmoid(cloud_mask_pred)\n",
    "        preds = (probs > 0.5).long()\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(cloud_mask_target.cpu().numpy())\n",
    "\n",
    "# Flatten predictions and labels\n",
    "all_preds = np.concatenate([p.flatten() for p in all_preds])\n",
    "all_labels = np.concatenate([l.flatten() for l in all_labels])\n",
    "\n",
    "# Classification report and IoU\n",
    "report = classification_report(\n",
    "    all_labels, all_preds,\n",
    "    labels=[0, 1],\n",
    "    digits=3,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "\n",
    "# Output\n",
    "print(\"CLOUD MASK REPORT:\\n\", classification_report(all_labels, all_preds, labels=[0, 1], digits=3))\n",
    "print(\"CONFUSION MATRIX:\\n\", confusion_matrix(all_labels, all_preds, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c8df5-d921-4eac-a8b9-b14e2eb94ea0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL EVALUATION — CLOUD PHASE\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _, cloud_phase_target, _, _ = unpack_labels(labels)\n",
    "        _, cloud_phase_pred, _, _ = model(images)\n",
    "        preds = torch.argmax(cloud_phase_pred, dim=1)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(cloud_phase_target.cpu().numpy())\n",
    "        \n",
    "# Flatten predictions and labels\n",
    "all_preds = np.concatenate([p.flatten() for p in all_preds])\n",
    "all_labels = np.concatenate([l.flatten() for l in all_labels])\n",
    "\n",
    "# Classification report and IoU\n",
    "report = classification_report(all_labels, all_preds, digits=3, output_dict=True)\n",
    "f1_scores = np.array([report[str(i)]['f1-score'] for i in range(num_classes)])\n",
    "supports = np.array([report[str(i)]['support'] for i in range(num_classes)])\n",
    "iou = f1_scores / (2 - f1_scores)\n",
    "\n",
    "# Output\n",
    "print(\"CLOUD PHASE REPORT:\\n\", classification_report(all_labels, all_preds, digits=3))\n",
    "print(\"CONFUSION MATRIX:\\n\", confusion_matrix(all_labels, all_preds))\n",
    "print(\"\\nIOU:\", iou)\n",
    "print(\"Unweighted IoU:\", np.mean(iou))\n",
    "print(\"Weighted IoU:\", np.average(iou, weights=supports))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6fa71-7e74-4f1b-8806-3891c037a1b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL EVALUATION — CLOUD OPTICAL DISTANCE\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _, _, cod_target, _ = unpack_labels(labels)\n",
    "        _, _, cod_pred, _ = model(images)\n",
    "        \n",
    "        all_preds.append(cod_pred.cpu().numpy().reshape(-1))\n",
    "        all_labels.append(cod_target.cpu().numpy().reshape(-1))\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(\"r2:\", r2_score(all_labels, all_preds))\n",
    "print(\"MSE:\", mean_squared_error(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968dce8-90fe-44ce-a25a-4e7125b0dfaf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL EVALUATION — CLOUD PARTICLE SIZE\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _, _, _, cps_target = unpack_labels(labels)\n",
    "        _, _, _, cps_pred = model(images)\n",
    "        \n",
    "        all_preds.append(cps_pred.cpu().numpy().reshape(-1))\n",
    "        all_labels.append(cps_target.cpu().numpy().reshape(-1))\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(\"r2:\", r2_score(all_labels, all_preds))\n",
    "print(\"MSE:\", mean_squared_error(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7c172-8b04-4fa5-83fc-1abf82a91b70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data_iter = iter(test_loader)\n",
    "# images, labels = next(data_iter)\n",
    "\n",
    "# images = images.to(device)\n",
    "# labels = labels.to(device)\n",
    "# _, cloud_phase_target, _, _ = unpack_labels(labels)\n",
    "# _, cloud_phase_pred, _, _ = model(images)\n",
    "# preds = torch.argmax(cloud_phase_pred, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90c778-93f2-4ebb-aadc-562b4177112a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# my_image = images[0].cpu().numpy()\n",
    "# my_image = np.transpose(my_image, (1, 2, 0))\n",
    "# phase_pred = preds[0].cpu().numpy()\n",
    "# phase_target = cloud_phase_target[0].cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "# from netCDF4 import Dataset\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# with Dataset('image1.nc', 'w', format='NETCDF4') as ds:\n",
    "#     ds.createDimension('x', my_image.shape[0])\n",
    "#     ds.createDimension('y', my_image.shape[1])\n",
    "#     ds.createDimension('band', my_image.shape[2])\n",
    "\n",
    "#     var = ds.createVariable('radiance', 'f4', ('x', 'y', 'band'))\n",
    "#     var[:] = my_image\n",
    "\n",
    "#     var.units = 'unknown'  # optional metadata\n",
    "\n",
    "# with Dataset('image2.nc', 'w', format='NETCDF4') as ds:\n",
    "#     ds.createDimension('x', phase_pred.shape[0])\n",
    "#     ds.createDimension('y', phase_pred.shape[1])\n",
    "\n",
    "#     var = ds.createVariable('prediction', 'f4', ('x', 'y'))\n",
    "#     var[:] = phase_pred\n",
    "\n",
    "#     var.units = 'unknown'  # optional metadata\n",
    "\n",
    "\n",
    "# with Dataset('image3.nc', 'w', format='NETCDF4') as ds:\n",
    "#     ds.createDimension('x', phase_target.shape[0])\n",
    "#     ds.createDimension('y', phase_target.shape[1])\n",
    "\n",
    "#     var = ds.createVariable('target', 'f4', ('x', 'y'))\n",
    "#     var[:] = phase_target\n",
    "\n",
    "#     var.units = 'unknown'  # optional metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb8600-6223-4768-9f5c-56a5550eec90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
