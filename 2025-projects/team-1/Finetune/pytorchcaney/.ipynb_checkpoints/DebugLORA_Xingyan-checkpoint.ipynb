{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7f5a0a-2e0e-43cb-af49-439eaef077d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-01 20:14:25,602] [WARNING] [real_accelerator.py:181:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2025-07-01 20:14:25,615] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /home/sj51939/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/umbc/rs/nasa-access/users/xingyan/software/miniconda3/envs/satvision/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/umbc/rs/nasa-access/users/xingyan/software/miniconda3/envs/satvision/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from phase_pred_pipeline import PhasePred\n",
    "from pytorch_caney.configs.config import _C, _update_config_from_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133ead1a-2446-4569-8908-10e630c96895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from configs/16bands.yaml\n"
     ]
    }
   ],
   "source": [
    "config_path = \"configs/16bands.yaml\"\n",
    "config = _C.clone()\n",
    "_update_config_from_file(config, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e29e0d3-ec7d-4714-8d53-741e45c5aeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_layer.weight:\n",
      "[LoRALinear] ΔW mean abs: 0.200789\n",
      "tensor([[ 0.1525,  0.0600,  0.2214,  0.0552,  0.1436],\n",
      "        [-0.0263, -0.2564,  0.0097, -0.0323, -0.4425],\n",
      "        [-0.7647,  0.3190,  0.2544, -0.2724, -0.1471]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Copied from phase_pred_pipeline.py\n",
    "class LoRALinear(nn.Module):\n",
    "    '''\n",
    "    Pasted from https://docs.pytorch.org/torchtune/0.4/tutorials/lora_finetune.html\n",
    "    This class can be called like LoRALinear(in_dim, out_dim, <module from satvision>, r, a, 0)\n",
    "    to replace layers in satvision, can do module = LoRALinear(...)\n",
    "    '''\n",
    "    def __init__(self, in_dim: int, out_dim: int, orig_layer, rank: int, alpha: float, dropout: float):\n",
    "        super().__init__()\n",
    "\n",
    "        # This is the weights/linear layer from the original pretrained model\n",
    "        self.orig = orig_layer\n",
    "\n",
    "        # These are the new LoRA params. In general rank << in_dim, out_dim\n",
    "        self.lora_a = nn.Linear(in_dim, rank, bias=False)\n",
    "        self.lora_b = nn.Linear(rank, out_dim, bias=False)\n",
    "\n",
    "        # Rank and alpha are commonly-tuned hyperparameters\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.scaling = self.alpha / self.rank\n",
    "\n",
    "        # Most implementations also include some dropout\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # The original params are frozen, and only LoRA params are trainable.\n",
    "        self.orig.weight.requires_grad = False\n",
    "        self.lora_a.weight.requires_grad = True\n",
    "        self.lora_b.weight.requires_grad = True\n",
    "    \n",
    "    @property\n",
    "    def weight(self):\n",
    "        # Combine base weight with the A/B weights\n",
    "        delta_w = self.scaling * (self.lora_b.weight @ self.lora_a.weight)\n",
    "        print(f\"[LoRALinear] ΔW mean abs: {delta_w.abs().mean().item():.6f}\")\n",
    "        combined = self.orig.weight + delta_w\n",
    "        return combined\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        \"\"\"Explicitly handle 'weight' attribute for PyTorch compatibility\"\"\"\n",
    "        if name == 'weight':\n",
    "            return self.weight  # Resolve via property\n",
    "        return super().__getattr__(name)\n",
    "\n",
    "# dummy test:\n",
    "orig_layer = nn.Linear(5, 3)\n",
    "lora_layer = LoRALinear(5, 3, orig_layer, rank=2, alpha=4.0, dropout=0.1)\n",
    "\n",
    "print(\"lora_layer.weight:\")\n",
    "print(lora_layer.weight)\n",
    "## This does indeed print a tensor, but calling .weight during runtime will error.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f44bb709-2b13-4bc0-a8fd-b1fc1dab0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fcn': <class 'pytorch_caney.models.encoders.fcn_encoder.FcnEncoder'>, 'swinv2': <class 'pytorch_caney.models.encoders.swinv2.SwinTransformerV2'>, 'satvision': <class 'pytorch_caney.models.encoders.satvision.SatVision'>}\n",
      "{'fcn': <class 'pytorch_caney.models.decoders.fcn_decoder.FcnDecoder'>}\n",
      "{'segmentation_head': <class 'pytorch_caney.models.heads.segmentation_head.SegmentationHead'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/umbc/rs/nasa-access/users/xingyan/software/miniconda3/envs/satvision/lib/python3.9/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_pretrained() called!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/umbc/rs/nasa-access/users/xingyan/Danielle/pytorchcaney/pytorch_caney/models/encoders/satvision.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect pre-trained model, remove [encoder.] prefix.\n",
      "After loading, patch_embed.proj.weight.shape: torch.Size([512, 14, 4, 4])\n",
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=['mask_token', 'layers.2.blocks.5.norm1.weight', 'layers.2.blocks.5.norm1.bias', 'layers.2.blocks.5.attn.logit_scale', 'layers.2.blocks.5.attn.q_bias', 'layers.2.blocks.5.attn.v_bias', 'layers.2.blocks.5.attn.relative_coords_table', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.5.attn.cpb_mlp.0.weight', 'layers.2.blocks.5.attn.cpb_mlp.0.bias', 'layers.2.blocks.5.attn.cpb_mlp.2.weight', 'layers.2.blocks.5.attn.qkv.weight', 'layers.2.blocks.5.attn.proj.weight', 'layers.2.blocks.5.attn.proj.bias', 'layers.2.blocks.5.norm2.weight', 'layers.2.blocks.5.norm2.bias', 'layers.2.blocks.5.norm3.weight', 'layers.2.blocks.5.norm3.bias', 'layers.2.blocks.5.mlp.fc1.weight', 'layers.2.blocks.5.mlp.fc1.bias', 'layers.2.blocks.5.mlp.fc2.weight', 'layers.2.blocks.5.mlp.fc2.bias', 'layers.2.blocks.6.norm1.weight', 'layers.2.blocks.6.norm1.bias', 'layers.2.blocks.6.attn.logit_scale', 'layers.2.blocks.6.attn.q_bias', 'layers.2.blocks.6.attn.v_bias', 'layers.2.blocks.6.attn.relative_coords_table', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.6.attn.cpb_mlp.0.weight', 'layers.2.blocks.6.attn.cpb_mlp.0.bias', 'layers.2.blocks.6.attn.cpb_mlp.2.weight', 'layers.2.blocks.6.attn.qkv.weight', 'layers.2.blocks.6.attn.proj.weight', 'layers.2.blocks.6.attn.proj.bias', 'layers.2.blocks.6.norm2.weight', 'layers.2.blocks.6.norm2.bias', 'layers.2.blocks.6.mlp.fc1.weight', 'layers.2.blocks.6.mlp.fc1.bias', 'layers.2.blocks.6.mlp.fc2.weight', 'layers.2.blocks.6.mlp.fc2.bias', 'layers.2.blocks.7.norm1.weight', 'layers.2.blocks.7.norm1.bias', 'layers.2.blocks.7.attn.logit_scale', 'layers.2.blocks.7.attn.q_bias', 'layers.2.blocks.7.attn.v_bias', 'layers.2.blocks.7.attn.relative_coords_table', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.7.attn.cpb_mlp.0.weight', 'layers.2.blocks.7.attn.cpb_mlp.0.bias', 'layers.2.blocks.7.attn.cpb_mlp.2.weight', 'layers.2.blocks.7.attn.qkv.weight', 'layers.2.blocks.7.attn.proj.weight', 'layers.2.blocks.7.attn.proj.bias', 'layers.2.blocks.7.norm2.weight', 'layers.2.blocks.7.norm2.bias', 'layers.2.blocks.7.mlp.fc1.weight', 'layers.2.blocks.7.mlp.fc1.bias', 'layers.2.blocks.7.mlp.fc2.weight', 'layers.2.blocks.7.mlp.fc2.bias', 'layers.2.blocks.8.norm1.weight', 'layers.2.blocks.8.norm1.bias', 'layers.2.blocks.8.attn.logit_scale', 'layers.2.blocks.8.attn.q_bias', 'layers.2.blocks.8.attn.v_bias', 'layers.2.blocks.8.attn.relative_coords_table', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.8.attn.cpb_mlp.0.weight', 'layers.2.blocks.8.attn.cpb_mlp.0.bias', 'layers.2.blocks.8.attn.cpb_mlp.2.weight', 'layers.2.blocks.8.attn.qkv.weight', 'layers.2.blocks.8.attn.proj.weight', 'layers.2.blocks.8.attn.proj.bias', 'layers.2.blocks.8.norm2.weight', 'layers.2.blocks.8.norm2.bias', 'layers.2.blocks.8.mlp.fc1.weight', 'layers.2.blocks.8.mlp.fc1.bias', 'layers.2.blocks.8.mlp.fc2.weight', 'layers.2.blocks.8.mlp.fc2.bias', 'layers.2.blocks.9.norm1.weight', 'layers.2.blocks.9.norm1.bias', 'layers.2.blocks.9.attn.logit_scale', 'layers.2.blocks.9.attn.q_bias', 'layers.2.blocks.9.attn.v_bias', 'layers.2.blocks.9.attn.relative_coords_table', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.9.attn.cpb_mlp.0.weight', 'layers.2.blocks.9.attn.cpb_mlp.0.bias', 'layers.2.blocks.9.attn.cpb_mlp.2.weight', 'layers.2.blocks.9.attn.qkv.weight', 'layers.2.blocks.9.attn.proj.weight', 'layers.2.blocks.9.attn.proj.bias', 'layers.2.blocks.9.norm2.weight', 'layers.2.blocks.9.norm2.bias', 'layers.2.blocks.9.mlp.fc1.weight', 'layers.2.blocks.9.mlp.fc1.bias', 'layers.2.blocks.9.mlp.fc2.weight', 'layers.2.blocks.9.mlp.fc2.bias', 'layers.2.blocks.10.norm1.weight', 'layers.2.blocks.10.norm1.bias', 'layers.2.blocks.10.attn.logit_scale', 'layers.2.blocks.10.attn.q_bias', 'layers.2.blocks.10.attn.v_bias', 'layers.2.blocks.10.attn.relative_coords_table', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.10.attn.cpb_mlp.0.weight', 'layers.2.blocks.10.attn.cpb_mlp.0.bias', 'layers.2.blocks.10.attn.cpb_mlp.2.weight', 'layers.2.blocks.10.attn.qkv.weight', 'layers.2.blocks.10.attn.proj.weight', 'layers.2.blocks.10.attn.proj.bias', 'layers.2.blocks.10.norm2.weight', 'layers.2.blocks.10.norm2.bias', 'layers.2.blocks.10.mlp.fc1.weight', 'layers.2.blocks.10.mlp.fc1.bias', 'layers.2.blocks.10.mlp.fc2.weight', 'layers.2.blocks.10.mlp.fc2.bias', 'layers.2.blocks.11.norm1.weight', 'layers.2.blocks.11.norm1.bias', 'layers.2.blocks.11.attn.logit_scale', 'layers.2.blocks.11.attn.q_bias', 'layers.2.blocks.11.attn.v_bias', 'layers.2.blocks.11.attn.relative_coords_table', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.11.attn.cpb_mlp.0.weight', 'layers.2.blocks.11.attn.cpb_mlp.0.bias', 'layers.2.blocks.11.attn.cpb_mlp.2.weight', 'layers.2.blocks.11.attn.qkv.weight', 'layers.2.blocks.11.attn.proj.weight', 'layers.2.blocks.11.attn.proj.bias', 'layers.2.blocks.11.norm2.weight', 'layers.2.blocks.11.norm2.bias', 'layers.2.blocks.11.norm3.weight', 'layers.2.blocks.11.norm3.bias', 'layers.2.blocks.11.mlp.fc1.weight', 'layers.2.blocks.11.mlp.fc1.bias', 'layers.2.blocks.11.mlp.fc2.weight', 'layers.2.blocks.11.mlp.fc2.bias', 'layers.2.blocks.12.norm1.weight', 'layers.2.blocks.12.norm1.bias', 'layers.2.blocks.12.attn.logit_scale', 'layers.2.blocks.12.attn.q_bias', 'layers.2.blocks.12.attn.v_bias', 'layers.2.blocks.12.attn.relative_coords_table', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.12.attn.cpb_mlp.0.weight', 'layers.2.blocks.12.attn.cpb_mlp.0.bias', 'layers.2.blocks.12.attn.cpb_mlp.2.weight', 'layers.2.blocks.12.attn.qkv.weight', 'layers.2.blocks.12.attn.proj.weight', 'layers.2.blocks.12.attn.proj.bias', 'layers.2.blocks.12.norm2.weight', 'layers.2.blocks.12.norm2.bias', 'layers.2.blocks.12.mlp.fc1.weight', 'layers.2.blocks.12.mlp.fc1.bias', 'layers.2.blocks.12.mlp.fc2.weight', 'layers.2.blocks.12.mlp.fc2.bias', 'layers.2.blocks.13.norm1.weight', 'layers.2.blocks.13.norm1.bias', 'layers.2.blocks.13.attn.logit_scale', 'layers.2.blocks.13.attn.q_bias', 'layers.2.blocks.13.attn.v_bias', 'layers.2.blocks.13.attn.relative_coords_table', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.13.attn.cpb_mlp.0.weight', 'layers.2.blocks.13.attn.cpb_mlp.0.bias', 'layers.2.blocks.13.attn.cpb_mlp.2.weight', 'layers.2.blocks.13.attn.qkv.weight', 'layers.2.blocks.13.attn.proj.weight', 'layers.2.blocks.13.attn.proj.bias', 'layers.2.blocks.13.norm2.weight', 'layers.2.blocks.13.norm2.bias', 'layers.2.blocks.13.mlp.fc1.weight', 'layers.2.blocks.13.mlp.fc1.bias', 'layers.2.blocks.13.mlp.fc2.weight', 'layers.2.blocks.13.mlp.fc2.bias', 'layers.2.blocks.14.norm1.weight', 'layers.2.blocks.14.norm1.bias', 'layers.2.blocks.14.attn.logit_scale', 'layers.2.blocks.14.attn.q_bias', 'layers.2.blocks.14.attn.v_bias', 'layers.2.blocks.14.attn.relative_coords_table', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.14.attn.cpb_mlp.0.weight', 'layers.2.blocks.14.attn.cpb_mlp.0.bias', 'layers.2.blocks.14.attn.cpb_mlp.2.weight', 'layers.2.blocks.14.attn.qkv.weight', 'layers.2.blocks.14.attn.proj.weight', 'layers.2.blocks.14.attn.proj.bias', 'layers.2.blocks.14.norm2.weight', 'layers.2.blocks.14.norm2.bias', 'layers.2.blocks.14.mlp.fc1.weight', 'layers.2.blocks.14.mlp.fc1.bias', 'layers.2.blocks.14.mlp.fc2.weight', 'layers.2.blocks.14.mlp.fc2.bias', 'layers.2.blocks.15.norm1.weight', 'layers.2.blocks.15.norm1.bias', 'layers.2.blocks.15.attn.logit_scale', 'layers.2.blocks.15.attn.q_bias', 'layers.2.blocks.15.attn.v_bias', 'layers.2.blocks.15.attn.relative_coords_table', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.15.attn.cpb_mlp.0.weight', 'layers.2.blocks.15.attn.cpb_mlp.0.bias', 'layers.2.blocks.15.attn.cpb_mlp.2.weight', 'layers.2.blocks.15.attn.qkv.weight', 'layers.2.blocks.15.attn.proj.weight', 'layers.2.blocks.15.attn.proj.bias', 'layers.2.blocks.15.norm2.weight', 'layers.2.blocks.15.norm2.bias', 'layers.2.blocks.15.mlp.fc1.weight', 'layers.2.blocks.15.mlp.fc1.bias', 'layers.2.blocks.15.mlp.fc2.weight', 'layers.2.blocks.15.mlp.fc2.bias', 'layers.2.blocks.16.norm1.weight', 'layers.2.blocks.16.norm1.bias', 'layers.2.blocks.16.attn.logit_scale', 'layers.2.blocks.16.attn.q_bias', 'layers.2.blocks.16.attn.v_bias', 'layers.2.blocks.16.attn.relative_coords_table', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.16.attn.cpb_mlp.0.weight', 'layers.2.blocks.16.attn.cpb_mlp.0.bias', 'layers.2.blocks.16.attn.cpb_mlp.2.weight', 'layers.2.blocks.16.attn.qkv.weight', 'layers.2.blocks.16.attn.proj.weight', 'layers.2.blocks.16.attn.proj.bias', 'layers.2.blocks.16.norm2.weight', 'layers.2.blocks.16.norm2.bias', 'layers.2.blocks.16.mlp.fc1.weight', 'layers.2.blocks.16.mlp.fc1.bias', 'layers.2.blocks.16.mlp.fc2.weight', 'layers.2.blocks.16.mlp.fc2.bias', 'layers.2.blocks.17.norm1.weight', 'layers.2.blocks.17.norm1.bias', 'layers.2.blocks.17.attn.logit_scale', 'layers.2.blocks.17.attn.q_bias', 'layers.2.blocks.17.attn.v_bias', 'layers.2.blocks.17.attn.relative_coords_table', 'layers.2.blocks.17.attn.relative_position_index', 'layers.2.blocks.17.attn.cpb_mlp.0.weight', 'layers.2.blocks.17.attn.cpb_mlp.0.bias', 'layers.2.blocks.17.attn.cpb_mlp.2.weight', 'layers.2.blocks.17.attn.qkv.weight', 'layers.2.blocks.17.attn.proj.weight', 'layers.2.blocks.17.attn.proj.bias', 'layers.2.blocks.17.norm2.weight', 'layers.2.blocks.17.norm2.bias', 'layers.2.blocks.17.norm3.weight', 'layers.2.blocks.17.norm3.bias', 'layers.2.blocks.17.mlp.fc1.weight', 'layers.2.blocks.17.mlp.fc1.bias', 'layers.2.blocks.17.mlp.fc2.weight', 'layers.2.blocks.17.mlp.fc2.bias', 'layers.2.blocks.18.norm1.weight', 'layers.2.blocks.18.norm1.bias', 'layers.2.blocks.18.attn.logit_scale', 'layers.2.blocks.18.attn.q_bias', 'layers.2.blocks.18.attn.v_bias', 'layers.2.blocks.18.attn.relative_coords_table', 'layers.2.blocks.18.attn.relative_position_index', 'layers.2.blocks.18.attn.cpb_mlp.0.weight', 'layers.2.blocks.18.attn.cpb_mlp.0.bias', 'layers.2.blocks.18.attn.cpb_mlp.2.weight', 'layers.2.blocks.18.attn.qkv.weight', 'layers.2.blocks.18.attn.proj.weight', 'layers.2.blocks.18.attn.proj.bias', 'layers.2.blocks.18.norm2.weight', 'layers.2.blocks.18.norm2.bias', 'layers.2.blocks.18.mlp.fc1.weight', 'layers.2.blocks.18.mlp.fc1.bias', 'layers.2.blocks.18.mlp.fc2.weight', 'layers.2.blocks.18.mlp.fc2.bias', 'layers.2.blocks.19.norm1.weight', 'layers.2.blocks.19.norm1.bias', 'layers.2.blocks.19.attn.logit_scale', 'layers.2.blocks.19.attn.q_bias', 'layers.2.blocks.19.attn.v_bias', 'layers.2.blocks.19.attn.relative_coords_table', 'layers.2.blocks.19.attn.relative_position_index', 'layers.2.blocks.19.attn.cpb_mlp.0.weight', 'layers.2.blocks.19.attn.cpb_mlp.0.bias', 'layers.2.blocks.19.attn.cpb_mlp.2.weight', 'layers.2.blocks.19.attn.qkv.weight', 'layers.2.blocks.19.attn.proj.weight', 'layers.2.blocks.19.attn.proj.bias', 'layers.2.blocks.19.norm2.weight', 'layers.2.blocks.19.norm2.bias', 'layers.2.blocks.19.mlp.fc1.weight', 'layers.2.blocks.19.mlp.fc1.bias', 'layers.2.blocks.19.mlp.fc2.weight', 'layers.2.blocks.19.mlp.fc2.bias', 'layers.2.blocks.20.norm1.weight', 'layers.2.blocks.20.norm1.bias', 'layers.2.blocks.20.attn.logit_scale', 'layers.2.blocks.20.attn.q_bias', 'layers.2.blocks.20.attn.v_bias', 'layers.2.blocks.20.attn.relative_coords_table', 'layers.2.blocks.20.attn.relative_position_index', 'layers.2.blocks.20.attn.cpb_mlp.0.weight', 'layers.2.blocks.20.attn.cpb_mlp.0.bias', 'layers.2.blocks.20.attn.cpb_mlp.2.weight', 'layers.2.blocks.20.attn.qkv.weight', 'layers.2.blocks.20.attn.proj.weight', 'layers.2.blocks.20.attn.proj.bias', 'layers.2.blocks.20.norm2.weight', 'layers.2.blocks.20.norm2.bias', 'layers.2.blocks.20.mlp.fc1.weight', 'layers.2.blocks.20.mlp.fc1.bias', 'layers.2.blocks.20.mlp.fc2.weight', 'layers.2.blocks.20.mlp.fc2.bias', 'layers.2.blocks.21.norm1.weight', 'layers.2.blocks.21.norm1.bias', 'layers.2.blocks.21.attn.logit_scale', 'layers.2.blocks.21.attn.q_bias', 'layers.2.blocks.21.attn.v_bias', 'layers.2.blocks.21.attn.relative_coords_table', 'layers.2.blocks.21.attn.relative_position_index', 'layers.2.blocks.21.attn.cpb_mlp.0.weight', 'layers.2.blocks.21.attn.cpb_mlp.0.bias', 'layers.2.blocks.21.attn.cpb_mlp.2.weight', 'layers.2.blocks.21.attn.qkv.weight', 'layers.2.blocks.21.attn.proj.weight', 'layers.2.blocks.21.attn.proj.bias', 'layers.2.blocks.21.norm2.weight', 'layers.2.blocks.21.norm2.bias', 'layers.2.blocks.21.mlp.fc1.weight', 'layers.2.blocks.21.mlp.fc1.bias', 'layers.2.blocks.21.mlp.fc2.weight', 'layers.2.blocks.21.mlp.fc2.bias', 'layers.2.blocks.22.norm1.weight', 'layers.2.blocks.22.norm1.bias', 'layers.2.blocks.22.attn.logit_scale', 'layers.2.blocks.22.attn.q_bias', 'layers.2.blocks.22.attn.v_bias', 'layers.2.blocks.22.attn.relative_coords_table', 'layers.2.blocks.22.attn.relative_position_index', 'layers.2.blocks.22.attn.cpb_mlp.0.weight', 'layers.2.blocks.22.attn.cpb_mlp.0.bias', 'layers.2.blocks.22.attn.cpb_mlp.2.weight', 'layers.2.blocks.22.attn.qkv.weight', 'layers.2.blocks.22.attn.proj.weight', 'layers.2.blocks.22.attn.proj.bias', 'layers.2.blocks.22.norm2.weight', 'layers.2.blocks.22.norm2.bias', 'layers.2.blocks.22.mlp.fc1.weight', 'layers.2.blocks.22.mlp.fc1.bias', 'layers.2.blocks.22.mlp.fc2.weight', 'layers.2.blocks.22.mlp.fc2.bias', 'layers.2.blocks.23.norm1.weight', 'layers.2.blocks.23.norm1.bias', 'layers.2.blocks.23.attn.logit_scale', 'layers.2.blocks.23.attn.q_bias', 'layers.2.blocks.23.attn.v_bias', 'layers.2.blocks.23.attn.relative_coords_table', 'layers.2.blocks.23.attn.relative_position_index', 'layers.2.blocks.23.attn.cpb_mlp.0.weight', 'layers.2.blocks.23.attn.cpb_mlp.0.bias', 'layers.2.blocks.23.attn.cpb_mlp.2.weight', 'layers.2.blocks.23.attn.qkv.weight', 'layers.2.blocks.23.attn.proj.weight', 'layers.2.blocks.23.attn.proj.bias', 'layers.2.blocks.23.norm2.weight', 'layers.2.blocks.23.norm2.bias', 'layers.2.blocks.23.norm3.weight', 'layers.2.blocks.23.norm3.bias', 'layers.2.blocks.23.mlp.fc1.weight', 'layers.2.blocks.23.mlp.fc1.bias', 'layers.2.blocks.23.mlp.fc2.weight', 'layers.2.blocks.23.mlp.fc2.bias', 'layers.2.blocks.24.norm1.weight', 'layers.2.blocks.24.norm1.bias', 'layers.2.blocks.24.attn.logit_scale', 'layers.2.blocks.24.attn.q_bias', 'layers.2.blocks.24.attn.v_bias', 'layers.2.blocks.24.attn.relative_coords_table', 'layers.2.blocks.24.attn.relative_position_index', 'layers.2.blocks.24.attn.cpb_mlp.0.weight', 'layers.2.blocks.24.attn.cpb_mlp.0.bias', 'layers.2.blocks.24.attn.cpb_mlp.2.weight', 'layers.2.blocks.24.attn.qkv.weight', 'layers.2.blocks.24.attn.proj.weight', 'layers.2.blocks.24.attn.proj.bias', 'layers.2.blocks.24.norm2.weight', 'layers.2.blocks.24.norm2.bias', 'layers.2.blocks.24.mlp.fc1.weight', 'layers.2.blocks.24.mlp.fc1.bias', 'layers.2.blocks.24.mlp.fc2.weight', 'layers.2.blocks.24.mlp.fc2.bias', 'layers.2.blocks.25.norm1.weight', 'layers.2.blocks.25.norm1.bias', 'layers.2.blocks.25.attn.logit_scale', 'layers.2.blocks.25.attn.q_bias', 'layers.2.blocks.25.attn.v_bias', 'layers.2.blocks.25.attn.relative_coords_table', 'layers.2.blocks.25.attn.relative_position_index', 'layers.2.blocks.25.attn.cpb_mlp.0.weight', 'layers.2.blocks.25.attn.cpb_mlp.0.bias', 'layers.2.blocks.25.attn.cpb_mlp.2.weight', 'layers.2.blocks.25.attn.qkv.weight', 'layers.2.blocks.25.attn.proj.weight', 'layers.2.blocks.25.attn.proj.bias', 'layers.2.blocks.25.norm2.weight', 'layers.2.blocks.25.norm2.bias', 'layers.2.blocks.25.mlp.fc1.weight', 'layers.2.blocks.25.mlp.fc1.bias', 'layers.2.blocks.25.mlp.fc2.weight', 'layers.2.blocks.25.mlp.fc2.bias', 'layers.2.blocks.26.norm1.weight', 'layers.2.blocks.26.norm1.bias', 'layers.2.blocks.26.attn.logit_scale', 'layers.2.blocks.26.attn.q_bias', 'layers.2.blocks.26.attn.v_bias', 'layers.2.blocks.26.attn.relative_coords_table', 'layers.2.blocks.26.attn.relative_position_index', 'layers.2.blocks.26.attn.cpb_mlp.0.weight', 'layers.2.blocks.26.attn.cpb_mlp.0.bias', 'layers.2.blocks.26.attn.cpb_mlp.2.weight', 'layers.2.blocks.26.attn.qkv.weight', 'layers.2.blocks.26.attn.proj.weight', 'layers.2.blocks.26.attn.proj.bias', 'layers.2.blocks.26.norm2.weight', 'layers.2.blocks.26.norm2.bias', 'layers.2.blocks.26.mlp.fc1.weight', 'layers.2.blocks.26.mlp.fc1.bias', 'layers.2.blocks.26.mlp.fc2.weight', 'layers.2.blocks.26.mlp.fc2.bias', 'layers.2.blocks.27.norm1.weight', 'layers.2.blocks.27.norm1.bias', 'layers.2.blocks.27.attn.logit_scale', 'layers.2.blocks.27.attn.q_bias', 'layers.2.blocks.27.attn.v_bias', 'layers.2.blocks.27.attn.relative_coords_table', 'layers.2.blocks.27.attn.relative_position_index', 'layers.2.blocks.27.attn.cpb_mlp.0.weight', 'layers.2.blocks.27.attn.cpb_mlp.0.bias', 'layers.2.blocks.27.attn.cpb_mlp.2.weight', 'layers.2.blocks.27.attn.qkv.weight', 'layers.2.blocks.27.attn.proj.weight', 'layers.2.blocks.27.attn.proj.bias', 'layers.2.blocks.27.norm2.weight', 'layers.2.blocks.27.norm2.bias', 'layers.2.blocks.27.mlp.fc1.weight', 'layers.2.blocks.27.mlp.fc1.bias', 'layers.2.blocks.27.mlp.fc2.weight', 'layers.2.blocks.27.mlp.fc2.bias', 'layers.2.blocks.28.norm1.weight', 'layers.2.blocks.28.norm1.bias', 'layers.2.blocks.28.attn.logit_scale', 'layers.2.blocks.28.attn.q_bias', 'layers.2.blocks.28.attn.v_bias', 'layers.2.blocks.28.attn.relative_coords_table', 'layers.2.blocks.28.attn.relative_position_index', 'layers.2.blocks.28.attn.cpb_mlp.0.weight', 'layers.2.blocks.28.attn.cpb_mlp.0.bias', 'layers.2.blocks.28.attn.cpb_mlp.2.weight', 'layers.2.blocks.28.attn.qkv.weight', 'layers.2.blocks.28.attn.proj.weight', 'layers.2.blocks.28.attn.proj.bias', 'layers.2.blocks.28.norm2.weight', 'layers.2.blocks.28.norm2.bias', 'layers.2.blocks.28.mlp.fc1.weight', 'layers.2.blocks.28.mlp.fc1.bias', 'layers.2.blocks.28.mlp.fc2.weight', 'layers.2.blocks.28.mlp.fc2.bias', 'layers.2.blocks.29.norm1.weight', 'layers.2.blocks.29.norm1.bias', 'layers.2.blocks.29.attn.logit_scale', 'layers.2.blocks.29.attn.q_bias', 'layers.2.blocks.29.attn.v_bias', 'layers.2.blocks.29.attn.relative_coords_table', 'layers.2.blocks.29.attn.relative_position_index', 'layers.2.blocks.29.attn.cpb_mlp.0.weight', 'layers.2.blocks.29.attn.cpb_mlp.0.bias', 'layers.2.blocks.29.attn.cpb_mlp.2.weight', 'layers.2.blocks.29.attn.qkv.weight', 'layers.2.blocks.29.attn.proj.weight', 'layers.2.blocks.29.attn.proj.bias', 'layers.2.blocks.29.norm2.weight', 'layers.2.blocks.29.norm2.bias', 'layers.2.blocks.29.norm3.weight', 'layers.2.blocks.29.norm3.bias', 'layers.2.blocks.29.mlp.fc1.weight', 'layers.2.blocks.29.mlp.fc1.bias', 'layers.2.blocks.29.mlp.fc2.weight', 'layers.2.blocks.29.mlp.fc2.bias', 'layers.2.blocks.30.norm1.weight', 'layers.2.blocks.30.norm1.bias', 'layers.2.blocks.30.attn.logit_scale', 'layers.2.blocks.30.attn.q_bias', 'layers.2.blocks.30.attn.v_bias', 'layers.2.blocks.30.attn.relative_coords_table', 'layers.2.blocks.30.attn.relative_position_index', 'layers.2.blocks.30.attn.cpb_mlp.0.weight', 'layers.2.blocks.30.attn.cpb_mlp.0.bias', 'layers.2.blocks.30.attn.cpb_mlp.2.weight', 'layers.2.blocks.30.attn.qkv.weight', 'layers.2.blocks.30.attn.proj.weight', 'layers.2.blocks.30.attn.proj.bias', 'layers.2.blocks.30.norm2.weight', 'layers.2.blocks.30.norm2.bias', 'layers.2.blocks.30.mlp.fc1.weight', 'layers.2.blocks.30.mlp.fc1.bias', 'layers.2.blocks.30.mlp.fc2.weight', 'layers.2.blocks.30.mlp.fc2.bias', 'layers.2.blocks.31.norm1.weight', 'layers.2.blocks.31.norm1.bias', 'layers.2.blocks.31.attn.logit_scale', 'layers.2.blocks.31.attn.q_bias', 'layers.2.blocks.31.attn.v_bias', 'layers.2.blocks.31.attn.relative_coords_table', 'layers.2.blocks.31.attn.relative_position_index', 'layers.2.blocks.31.attn.cpb_mlp.0.weight', 'layers.2.blocks.31.attn.cpb_mlp.0.bias', 'layers.2.blocks.31.attn.cpb_mlp.2.weight', 'layers.2.blocks.31.attn.qkv.weight', 'layers.2.blocks.31.attn.proj.weight', 'layers.2.blocks.31.attn.proj.bias', 'layers.2.blocks.31.norm2.weight', 'layers.2.blocks.31.norm2.bias', 'layers.2.blocks.31.mlp.fc1.weight', 'layers.2.blocks.31.mlp.fc1.bias', 'layers.2.blocks.31.mlp.fc2.weight', 'layers.2.blocks.31.mlp.fc2.bias', 'layers.2.blocks.32.norm1.weight', 'layers.2.blocks.32.norm1.bias', 'layers.2.blocks.32.attn.logit_scale', 'layers.2.blocks.32.attn.q_bias', 'layers.2.blocks.32.attn.v_bias', 'layers.2.blocks.32.attn.relative_coords_table', 'layers.2.blocks.32.attn.relative_position_index', 'layers.2.blocks.32.attn.cpb_mlp.0.weight', 'layers.2.blocks.32.attn.cpb_mlp.0.bias', 'layers.2.blocks.32.attn.cpb_mlp.2.weight', 'layers.2.blocks.32.attn.qkv.weight', 'layers.2.blocks.32.attn.proj.weight', 'layers.2.blocks.32.attn.proj.bias', 'layers.2.blocks.32.norm2.weight', 'layers.2.blocks.32.norm2.bias', 'layers.2.blocks.32.mlp.fc1.weight', 'layers.2.blocks.32.mlp.fc1.bias', 'layers.2.blocks.32.mlp.fc2.weight', 'layers.2.blocks.32.mlp.fc2.bias', 'layers.2.blocks.33.norm1.weight', 'layers.2.blocks.33.norm1.bias', 'layers.2.blocks.33.attn.logit_scale', 'layers.2.blocks.33.attn.q_bias', 'layers.2.blocks.33.attn.v_bias', 'layers.2.blocks.33.attn.relative_coords_table', 'layers.2.blocks.33.attn.relative_position_index', 'layers.2.blocks.33.attn.cpb_mlp.0.weight', 'layers.2.blocks.33.attn.cpb_mlp.0.bias', 'layers.2.blocks.33.attn.cpb_mlp.2.weight', 'layers.2.blocks.33.attn.qkv.weight', 'layers.2.blocks.33.attn.proj.weight', 'layers.2.blocks.33.attn.proj.bias', 'layers.2.blocks.33.norm2.weight', 'layers.2.blocks.33.norm2.bias', 'layers.2.blocks.33.mlp.fc1.weight', 'layers.2.blocks.33.mlp.fc1.bias', 'layers.2.blocks.33.mlp.fc2.weight', 'layers.2.blocks.33.mlp.fc2.bias', 'layers.2.blocks.34.norm1.weight', 'layers.2.blocks.34.norm1.bias', 'layers.2.blocks.34.attn.logit_scale', 'layers.2.blocks.34.attn.q_bias', 'layers.2.blocks.34.attn.v_bias', 'layers.2.blocks.34.attn.relative_coords_table', 'layers.2.blocks.34.attn.relative_position_index', 'layers.2.blocks.34.attn.cpb_mlp.0.weight', 'layers.2.blocks.34.attn.cpb_mlp.0.bias', 'layers.2.blocks.34.attn.cpb_mlp.2.weight', 'layers.2.blocks.34.attn.qkv.weight', 'layers.2.blocks.34.attn.proj.weight', 'layers.2.blocks.34.attn.proj.bias', 'layers.2.blocks.34.norm2.weight', 'layers.2.blocks.34.norm2.bias', 'layers.2.blocks.34.mlp.fc1.weight', 'layers.2.blocks.34.mlp.fc1.bias', 'layers.2.blocks.34.mlp.fc2.weight', 'layers.2.blocks.34.mlp.fc2.bias', 'layers.2.blocks.35.norm1.weight', 'layers.2.blocks.35.norm1.bias', 'layers.2.blocks.35.attn.logit_scale', 'layers.2.blocks.35.attn.q_bias', 'layers.2.blocks.35.attn.v_bias', 'layers.2.blocks.35.attn.relative_coords_table', 'layers.2.blocks.35.attn.relative_position_index', 'layers.2.blocks.35.attn.cpb_mlp.0.weight', 'layers.2.blocks.35.attn.cpb_mlp.0.bias', 'layers.2.blocks.35.attn.cpb_mlp.2.weight', 'layers.2.blocks.35.attn.qkv.weight', 'layers.2.blocks.35.attn.proj.weight', 'layers.2.blocks.35.attn.proj.bias', 'layers.2.blocks.35.norm2.weight', 'layers.2.blocks.35.norm2.bias', 'layers.2.blocks.35.norm3.weight', 'layers.2.blocks.35.norm3.bias', 'layers.2.blocks.35.mlp.fc1.weight', 'layers.2.blocks.35.mlp.fc1.bias', 'layers.2.blocks.35.mlp.fc2.weight', 'layers.2.blocks.35.mlp.fc2.bias', 'layers.2.blocks.36.norm1.weight', 'layers.2.blocks.36.norm1.bias', 'layers.2.blocks.36.attn.logit_scale', 'layers.2.blocks.36.attn.q_bias', 'layers.2.blocks.36.attn.v_bias', 'layers.2.blocks.36.attn.relative_coords_table', 'layers.2.blocks.36.attn.relative_position_index', 'layers.2.blocks.36.attn.cpb_mlp.0.weight', 'layers.2.blocks.36.attn.cpb_mlp.0.bias', 'layers.2.blocks.36.attn.cpb_mlp.2.weight', 'layers.2.blocks.36.attn.qkv.weight', 'layers.2.blocks.36.attn.proj.weight', 'layers.2.blocks.36.attn.proj.bias', 'layers.2.blocks.36.norm2.weight', 'layers.2.blocks.36.norm2.bias', 'layers.2.blocks.36.mlp.fc1.weight', 'layers.2.blocks.36.mlp.fc1.bias', 'layers.2.blocks.36.mlp.fc2.weight', 'layers.2.blocks.36.mlp.fc2.bias', 'layers.2.blocks.37.norm1.weight', 'layers.2.blocks.37.norm1.bias', 'layers.2.blocks.37.attn.logit_scale', 'layers.2.blocks.37.attn.q_bias', 'layers.2.blocks.37.attn.v_bias', 'layers.2.blocks.37.attn.relative_coords_table', 'layers.2.blocks.37.attn.relative_position_index', 'layers.2.blocks.37.attn.cpb_mlp.0.weight', 'layers.2.blocks.37.attn.cpb_mlp.0.bias', 'layers.2.blocks.37.attn.cpb_mlp.2.weight', 'layers.2.blocks.37.attn.qkv.weight', 'layers.2.blocks.37.attn.proj.weight', 'layers.2.blocks.37.attn.proj.bias', 'layers.2.blocks.37.norm2.weight', 'layers.2.blocks.37.norm2.bias', 'layers.2.blocks.37.mlp.fc1.weight', 'layers.2.blocks.37.mlp.fc1.bias', 'layers.2.blocks.37.mlp.fc2.weight', 'layers.2.blocks.37.mlp.fc2.bias', 'layers.2.blocks.38.norm1.weight', 'layers.2.blocks.38.norm1.bias', 'layers.2.blocks.38.attn.logit_scale', 'layers.2.blocks.38.attn.q_bias', 'layers.2.blocks.38.attn.v_bias', 'layers.2.blocks.38.attn.relative_coords_table', 'layers.2.blocks.38.attn.relative_position_index', 'layers.2.blocks.38.attn.cpb_mlp.0.weight', 'layers.2.blocks.38.attn.cpb_mlp.0.bias', 'layers.2.blocks.38.attn.cpb_mlp.2.weight', 'layers.2.blocks.38.attn.qkv.weight', 'layers.2.blocks.38.attn.proj.weight', 'layers.2.blocks.38.attn.proj.bias', 'layers.2.blocks.38.norm2.weight', 'layers.2.blocks.38.norm2.bias', 'layers.2.blocks.38.mlp.fc1.weight', 'layers.2.blocks.38.mlp.fc1.bias', 'layers.2.blocks.38.mlp.fc2.weight', 'layers.2.blocks.38.mlp.fc2.bias', 'layers.2.blocks.39.norm1.weight', 'layers.2.blocks.39.norm1.bias', 'layers.2.blocks.39.attn.logit_scale', 'layers.2.blocks.39.attn.q_bias', 'layers.2.blocks.39.attn.v_bias', 'layers.2.blocks.39.attn.relative_coords_table', 'layers.2.blocks.39.attn.relative_position_index', 'layers.2.blocks.39.attn.cpb_mlp.0.weight', 'layers.2.blocks.39.attn.cpb_mlp.0.bias', 'layers.2.blocks.39.attn.cpb_mlp.2.weight', 'layers.2.blocks.39.attn.qkv.weight', 'layers.2.blocks.39.attn.proj.weight', 'layers.2.blocks.39.attn.proj.bias', 'layers.2.blocks.39.norm2.weight', 'layers.2.blocks.39.norm2.bias', 'layers.2.blocks.39.mlp.fc1.weight', 'layers.2.blocks.39.mlp.fc1.bias', 'layers.2.blocks.39.mlp.fc2.weight', 'layers.2.blocks.39.mlp.fc2.bias', 'layers.2.blocks.40.norm1.weight', 'layers.2.blocks.40.norm1.bias', 'layers.2.blocks.40.attn.logit_scale', 'layers.2.blocks.40.attn.q_bias', 'layers.2.blocks.40.attn.v_bias', 'layers.2.blocks.40.attn.relative_coords_table', 'layers.2.blocks.40.attn.relative_position_index', 'layers.2.blocks.40.attn.cpb_mlp.0.weight', 'layers.2.blocks.40.attn.cpb_mlp.0.bias', 'layers.2.blocks.40.attn.cpb_mlp.2.weight', 'layers.2.blocks.40.attn.qkv.weight', 'layers.2.blocks.40.attn.proj.weight', 'layers.2.blocks.40.attn.proj.bias', 'layers.2.blocks.40.norm2.weight', 'layers.2.blocks.40.norm2.bias', 'layers.2.blocks.40.mlp.fc1.weight', 'layers.2.blocks.40.mlp.fc1.bias', 'layers.2.blocks.40.mlp.fc2.weight', 'layers.2.blocks.40.mlp.fc2.bias', 'layers.2.blocks.41.norm1.weight', 'layers.2.blocks.41.norm1.bias', 'layers.2.blocks.41.attn.logit_scale', 'layers.2.blocks.41.attn.q_bias', 'layers.2.blocks.41.attn.v_bias', 'layers.2.blocks.41.attn.relative_coords_table', 'layers.2.blocks.41.attn.relative_position_index', 'layers.2.blocks.41.attn.cpb_mlp.0.weight', 'layers.2.blocks.41.attn.cpb_mlp.0.bias', 'layers.2.blocks.41.attn.cpb_mlp.2.weight', 'layers.2.blocks.41.attn.qkv.weight', 'layers.2.blocks.41.attn.proj.weight', 'layers.2.blocks.41.attn.proj.bias', 'layers.2.blocks.41.norm2.weight', 'layers.2.blocks.41.norm2.bias', 'layers.2.blocks.41.norm3.weight', 'layers.2.blocks.41.norm3.bias', 'layers.2.blocks.41.mlp.fc1.weight', 'layers.2.blocks.41.mlp.fc1.bias', 'layers.2.blocks.41.mlp.fc2.weight', 'layers.2.blocks.41.mlp.fc2.bias'])\n",
      ">>>>>>> loaded successfully '/umbc/rs/nasa-access/users/xingyan/pytorch-caney/satvision-toa-giant-patch8-window8-128/mp_rank_00_model_states.pt'\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=512, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=16\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=512, out_features=1536, bias=False)\n",
      "    (lora_a): Linear(in_features=512, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=1536, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=512, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=16\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=512, out_features=1536, bias=False)\n",
      "    (lora_a): Linear(in_features=512, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=1536, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=1024, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=32\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "    (lora_a): Linear(in_features=1024, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=3072, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=1024, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=32\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "    (lora_a): Linear(in_features=1024, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=3072, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=2048, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=64\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "    (lora_a): Linear(in_features=2048, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=6144, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=2048, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=64\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "    (lora_a): Linear(in_features=2048, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=6144, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=2048, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=64\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "    (lora_a): Linear(in_features=2048, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=6144, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=2048, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=64\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "    (lora_a): Linear(in_features=2048, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=6144, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=2048, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=64\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "    (lora_a): Linear(in_features=2048, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=6144, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=4096, window_size=(4, 4), pretrained_window_size=(0, 0), num_heads=128\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=128, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "    (lora_a): Linear(in_features=4096, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=12288, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "Replaced layer 'qkv' in \n",
      "WindowAttention(\n",
      "  dim=4096, window_size=(4, 4), pretrained_window_size=(0, 0), num_heads=128\n",
      "  (cpb_mlp): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=128, bias=False)\n",
      "  )\n",
      "  (qkv): LoRALinear(\n",
      "    (orig): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "    (lora_a): Linear(in_features=4096, out_features=4, bias=False)\n",
      "    (lora_b): Linear(in_features=4, out_features=12288, bias=False)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      " with LoRA\n",
      "{'fcn': <class 'pytorch_caney.models.encoders.fcn_encoder.FcnEncoder'>, 'swinv2': <class 'pytorch_caney.models.encoders.swinv2.SwinTransformerV2'>, 'satvision': <class 'pytorch_caney.models.encoders.satvision.SatVision'>}\n",
      "{'fcn': <class 'pytorch_caney.models.decoders.fcn_decoder.FcnDecoder'>}\n",
      "{'segmentation_head': <class 'pytorch_caney.models.heads.segmentation_head.SegmentationHead'>}\n",
      "{'fcn': <class 'pytorch_caney.models.encoders.fcn_encoder.FcnEncoder'>, 'swinv2': <class 'pytorch_caney.models.encoders.swinv2.SwinTransformerV2'>, 'satvision': <class 'pytorch_caney.models.encoders.satvision.SatVision'>}\n",
      "{'fcn': <class 'pytorch_caney.models.decoders.fcn_decoder.FcnDecoder'>}\n",
      "{'segmentation_head': <class 'pytorch_caney.models.heads.segmentation_head.SegmentationHead'>}\n"
     ]
    }
   ],
   "source": [
    "model = PhasePred(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf56564-92b2-4e0a-9583-82ce03184089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRALinear] ΔW mean abs: 0.047224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0053, -0.1570, -0.0471,  ...,  0.0592,  0.0125,  0.1489],\n",
       "        [ 0.0441, -0.0424, -0.0444,  ..., -0.0040,  0.1016,  0.0408],\n",
       "        [-0.0309, -0.0665, -0.0556,  ...,  0.0447,  0.0642, -0.0029],\n",
       "        ...,\n",
       "        [ 0.0363,  0.1297,  0.0538,  ..., -0.0646,  0.0556, -0.2189],\n",
       "        [-0.0345, -0.2357, -0.1054,  ...,  0.0439, -0.0286, -0.0298],\n",
       "        [ 0.0036,  0.0510, -0.0474,  ..., -0.0027,  0.0769, -0.0277]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.model.layers[0].blocks[0].attn.qkv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d80b2bb1-95da-4797-a0de-d427440b5710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<property object at 0x1552ee611310>\n"
     ]
    }
   ],
   "source": [
    "qkv = model.encoder.model.layers[0].blocks[0].attn.qkv\n",
    "print(getattr(type(lora_layer), 'weight', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49c2d71e-ae5e-4e36-9435-cfb2e5c4478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qkv type: <class 'phase_pred_pipeline.LoRALinear'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"qkv type:\", type(qkv))\n",
    "#print(\"qkv.weight type:\", type(qkv.weight))\n",
    "#print(\"qkv.weight shape:\", qkv.weight.shape if isinstance(qkv.weight, torch.Tensor) else \"NOT a tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fe67d-ff7a-487f-be6c-ca988e0123b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
